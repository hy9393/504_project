{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/hwiyoung_park/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid objective: crossentropy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-0091063ccb58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_architecture_modified.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobjectives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjectives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_function\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/objectives.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'objective'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mget_from_module\u001b[0;34m(identifier, module_params, module_name, instantiate, kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             raise ValueError('Invalid ' + str(module_name) + ': ' +\n\u001b[0;32m--> 125\u001b[0;31m                              str(identifier))\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minstantiate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid objective: crossentropy"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "with open('model_architecture_modified.json', 'r') as f:\n",
    "    model1 = model_from_json(f.read())\n",
    "    model1.compile(optimizer='adadelta', metrics=['accuracy'], loss='crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GEOCODE_BASE_URL = \"https://maps.googleapis.com/maps/api/geocode/json?address=\"\n",
    "\n",
    "wb = pd.read_excel('DDW_PCA1024_2011_MDDS with UI.xlsx', sheet_name='Sheet1')\n",
    "rows, cols = wb.shape\n",
    "\n",
    "f1 = open('region_info_train.csv', 'w', encoding='utf-8', newline='')\n",
    "#f2 = open('region_info_valid.csv', 'w', encoding='utf-8', newline='')\n",
    "#f3 = open('region_info_test.csv', 'w', encoding='utf-8', newline='')\n",
    "wr1 = csv.writer(f1)\n",
    "#wr2 = csv.writer(f2)\n",
    "#wr3 = csv.writer(f3)\n",
    "wr1.writerow(['village_code', 'village_name', 'district_code', 'subdistrict_code', 'num_households', 'centre_lat', 'centre_lng'])\n",
    "#wr2.writerow(['village_code', 'village_name', 'subdistrict_code', 'num_households', 'centre_lat', 'centre_lng'])\n",
    "#wr3.writerow(['village_code', 'village_name', 'subdistrict_code', 'num_households', 'centre_lat', 'centre_lng'])\n",
    "\n",
    "check = 0\n",
    "\n",
    "for r in range(rows):\n",
    "    if r * 100 / rows >= check:\n",
    "        print(check, \"% done!\")\n",
    "        check += 1\n",
    "        \n",
    "    #if wb.iloc[r, 3] != 0 and wb.iloc[r, 4] == 0 and wb.iloc[r, 9] >= 100\"\"\"and r < rows*0.8\"\"\":\n",
    "    if wb.iloc[r, 3] != 0 and wb.iloc[r, 4] == 0 and wb.iloc[r, 9] >= 100:\n",
    "        #print(wb.iloc[r, 3], wb.iloc[r, 7])\n",
    "        \n",
    "        url = GEOCODE_BASE_URL + wb.iloc[r, 7].replace(\" \", \"+\") + \"&components=country:IN&key=AIzaSyAg5p0OR-RG5an0GzzhhcoRD-FD7bDOcz4\"\n",
    "        response = simplejson.load(urllib.request.urlopen(url))\n",
    "        if len(response['results']) != 0:\n",
    "            lat = response['results'][0]['geometry']['location']['lat']\n",
    "            lng = response['results'][0]['geometry']['location']['lng']\n",
    "        \n",
    "            wr1.writerow([wb.iloc[r, 3], wb.iloc[r, 7], wb.iloc[r, 1], wb.iloc[r, 2], wb.iloc[r, 9], round(lat, 7), round(lng, 7)])\n",
    "    \"\"\"    \n",
    "    elif wb.iloc[r, 3] != 0 and wb.iloc[r, 4] == 0 and wb.iloc[r, 9] >= 100 and r < rows*0.9:\n",
    "        #print(wb.iloc[r, 3], wb.iloc[r, 7])\n",
    "        \n",
    "        url = GEOCODE_BASE_URL + wb.iloc[r, 7].replace(\" \", \"+\") + \"&components=country:IN&key=AIzaSyAg5p0OR-RG5an0GzzhhcoRD-FD7bDOcz4\"\n",
    "        response = simplejson.load(urllib.request.urlopen(url))\n",
    "        if len(response['results']) != 0:\n",
    "            lat = response['results'][0]['geometry']['location']['lat']\n",
    "            lng = response['results'][0]['geometry']['location']['lng']\n",
    "        \n",
    "            wr2.writerow([wb.iloc[r, 3], wb.iloc[r, 7], wb.iloc[r, 2], wb.iloc[r, 9], round(lat, 7), round(lng, 7)])\n",
    "        \n",
    "    elif wb.iloc[r, 3] != 0 and wb.iloc[r, 4] == 0 and wb.iloc[r, 9] >= 100:\n",
    "        #print(wb.iloc[r, 3], wb.iloc[r, 7])\n",
    "        \n",
    "        url = GEOCODE_BASE_URL + wb.iloc[r, 7].replace(\" \", \"+\") + \"&components=country:IN&key=AIzaSyAg5p0OR-RG5an0GzzhhcoRD-FD7bDOcz4\"\n",
    "        response = simplejson.load(urllib.request.urlopen(url))\n",
    "        if len(response['results']) != 0:\n",
    "            lat = response['results'][0]['geometry']['location']['lat']\n",
    "            lng = response['results'][0]['geometry']['location']['lng']\n",
    "        \n",
    "            wr3.writerow([wb.iloc[r, 3], wb.iloc[r, 7], wb.iloc[r, 2], wb.iloc[r, 9], round(lat, 7), round(lng, 7)])\n",
    "   \"\"\"     \n",
    "f1.close()\n",
    "#f2.close()\n",
    "#f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 % done!\n",
      "1 % done!\n",
      "2 % done!\n",
      "3 % done!\n",
      "4 % done!\n",
      "5 % done!\n",
      "6 % done!\n",
      "7 % done!\n",
      "8 % done!\n",
      "9 % done!\n",
      "10 % done!\n",
      "11 % done!\n",
      "12 % done!\n",
      "13 % done!\n",
      "14 % done!\n",
      "15 % done!\n",
      "16 % done!\n",
      "17 % done!\n",
      "18 % done!\n",
      "19 % done!\n",
      "20 % done!\n",
      "21 % done!\n",
      "22 % done!\n",
      "23 % done!\n",
      "24 % done!\n",
      "25 % done!\n",
      "26 % done!\n",
      "27 % done!\n",
      "28 % done!\n",
      "29 % done!\n",
      "30 % done!\n",
      "31 % done!\n",
      "32 % done!\n",
      "33 % done!\n",
      "34 % done!\n",
      "35 % done!\n",
      "36 % done!\n",
      "37 % done!\n",
      "38 % done!\n",
      "39 % done!\n",
      "40 % done!\n",
      "41 % done!\n",
      "42 % done!\n",
      "43 % done!\n",
      "44 % done!\n",
      "45 % done!\n",
      "46 % done!\n",
      "47 % done!\n",
      "48 % done!\n",
      "49 % done!\n",
      "50 % done!\n",
      "51 % done!\n",
      "52 % done!\n",
      "53 % done!\n",
      "54 % done!\n",
      "55 % done!\n",
      "56 % done!\n",
      "57 % done!\n",
      "58 % done!\n",
      "59 % done!\n",
      "60 % done!\n",
      "61 % done!\n",
      "62 % done!\n",
      "63 % done!\n",
      "64 % done!\n",
      "65 % done!\n",
      "66 % done!\n",
      "67 % done!\n",
      "68 % done!\n",
      "69 % done!\n",
      "70 % done!\n",
      "71 % done!\n",
      "72 % done!\n",
      "73 % done!\n",
      "74 % done!\n",
      "75 % done!\n",
      "76 % done!\n",
      "77 % done!\n",
      "78 % done!\n",
      "79 % done!\n",
      "80 % done!\n",
      "81 % done!\n",
      "82 % done!\n",
      "83 % done!\n",
      "84 % done!\n",
      "85 % done!\n",
      "86 % done!\n",
      "87 % done!\n",
      "88 % done!\n",
      "89 % done!\n",
      "90 % done!\n",
      "91 % done!\n",
      "92 % done!\n",
      "93 % done!\n",
      "94 % done!\n",
      "95 % done!\n",
      "96 % done!\n",
      "97 % done!\n",
      "98 % done!\n",
      "99 % done!\n"
     ]
    }
   ],
   "source": [
    "wb = pd.read_excel('HLPCA-10226-2011_H14_census.xlsx', sheet_name='Sheet1')\n",
    "rows, cols = wb.shape\n",
    "\n",
    "f1 = open('region_info_train_y.csv', 'w', encoding='utf-8', newline='')\n",
    "wr1 = csv.writer(f1)\n",
    "wr1.writerow(['village_code', '0_0', '0_1', '0_2', '0_3', '0_4', '0_5', '0_6', '0_7', '0_8', '1_0', '1_1', '1_2', '1_3', '1_4', '1_5', '2_0', '2_1', '2_2', '2_3', '2_4', '2_5', '2_6', '2_7', '2_8', '2_9'])\n",
    "\n",
    "check = 0\n",
    "for r in range(rows):\n",
    "    if r * 100 / rows >= check:\n",
    "        print(check, \"% done!\")\n",
    "        check += 1\n",
    "        \n",
    "    if wb.iloc[r, 6] != '000000' and wb.iloc[r, 7] == '0000':\n",
    "        wr1.writerow([int(wb.iloc[r, 6]), round(wb.iloc[r, 22]/100, 3), round(wb.iloc[r, 23]/100, 3), round(wb.iloc[r, 24]/100, 3), round(wb.iloc[r, 25]/100, 3), round(wb.iloc[r, 26]/100, 3), round(wb.iloc[r, 27]/100, 3), round(wb.iloc[r, 28]/100, 3), round(wb.iloc[r, 29]/100, 3), round(wb.iloc[r, 30]/100, 3), round(wb.iloc[r, 84]/100, 3), round(wb.iloc[r, 85]/100, 3), round(wb.iloc[r, 86]/100, 3), round(wb.iloc[r, 87]/100, 3), round(wb.iloc[r, 88]/100, 3), round(wb.iloc[r, 89]/100, 3), round(wb.iloc[r, 71]/100, 3), round(wb.iloc[r, 72]/100, 3), round(wb.iloc[r, 73]/100, 3), round(wb.iloc[r, 74]/100, 3), round(wb.iloc[r, 75]/100, 3), round(wb.iloc[r, 76]/100, 3), round(wb.iloc[r, 77]/100, 3), round(wb.iloc[r, 78]/100, 3), round(wb.iloc[r, 79]/100, 3), round(wb.iloc[r, 80]/100, 3)])\n",
    "        \n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current :  1 / 39\n",
      "Current :  2 / 39\n",
      "Current :  3 / 39\n",
      "Current :  4 / 39\n",
      "Current :  5 / 39\n",
      "Current :  6 / 39\n",
      "Current :  7 / 39\n",
      "Current :  8 / 39\n",
      "Current :  9 / 39\n",
      "Current :  10 / 39\n",
      "Current :  11 / 39\n",
      "Current :  12 / 39\n",
      "Current :  13 / 39\n",
      "Current :  14 / 39\n",
      "Current :  15 / 39\n",
      "Current :  16 / 39\n",
      "Current :  17 / 39\n",
      "Current :  18 / 39\n",
      "Current :  19 / 39\n",
      "Current :  20 / 39\n",
      "Current :  21 / 39\n",
      "Current :  22 / 39\n",
      "Current :  23 / 39\n",
      "Current :  24 / 39\n",
      "Current :  25 / 39\n",
      "Current :  26 / 39\n",
      "Current :  27 / 39\n",
      "Current :  28 / 39\n",
      "Current :  29 / 39\n",
      "Current :  30 / 39\n",
      "Current :  31 / 39\n",
      "Current :  32 / 39\n",
      "Current :  33 / 39\n",
      "Current :  34 / 39\n",
      "Current :  35 / 39\n",
      "Current :  36 / 39\n",
      "Current :  37 / 39\n",
      "Current :  38 / 39\n",
      "Current :  39 / 39\n"
     ]
    }
   ],
   "source": [
    "LOCCODE_BASE_URL = \"https://maps.googleapis.com/maps/api/staticmap?center=\"\n",
    "\n",
    "f1 = pd.read_csv('region_info_train.csv')\n",
    "f2 = pd.read_csv('region_info_train_y.csv')\n",
    "\"\"\"\n",
    "url = LOCCODE_BASE_URL + str(f1.iloc[0, 5]) + \",\" + str(f1.iloc[0, 6]) + \"&zoom=16&size=1920x1920&maptype=satellite&key=AIzaSyAg5p0OR-RG5an0GzzhhcoRD-FD7bDOcz4\"\n",
    "img = Image.open(urllib.request.urlopen(url)).convert(\"RGB\")\n",
    "img.show()\n",
    "\n",
    "#village_code = 242473\n",
    "#temp = np.array(f2[(f2.village_code == village_code)])\n",
    "#print(temp[0, 1:])\n",
    "\"\"\"\n",
    "rows, cols = f1.shape\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "for i in range(rows//10):\n",
    "    print(\"Current : \", i+1, \"/\", rows//10)\n",
    "    count = 0\n",
    "    if (i+1)*10 > rows:\n",
    "        X = np.zeros(((i+1)*10 - rows, 640, 640, 3))\n",
    "        y = np.zeros(((i+1)*10 - rows, 25))\n",
    "        for j in range(i*10, rows):\n",
    "            url = LOCCODE_BASE_URL + str(f1.iloc[j, 5]) + \",\" + str(f1.iloc[j, 6]) + \"&zoom=16&size=1920x1920&maptype=satellite&key=AIzaSyAg5p0OR-RG5an0GzzhhcoRD-FD7bDOcz4\"\n",
    "            img = Image.open(urllib.request.urlopen(url)).convert(\"RGB\")\n",
    "            img = np.array(img)\n",
    "            X[count, :, :, :] = img\n",
    "            \n",
    "            village_code = f1.iloc[j, 0]\n",
    "            y[count, :] = np.array(f2[(f2.village_code == village_code)])[0, 1:]\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "    else:\n",
    "        X = np.zeros((batch_size, 640, 640, 3))\n",
    "        y = np.zeros((batch_size, 25))\n",
    "        for j in range(i*10, (i+1)*10):\n",
    "            url = LOCCODE_BASE_URL + str(f1.iloc[j, 5]) + \",\" + str(f1.iloc[j, 6]) + \"&zoom=16&size=1920x1920&maptype=satellite&key=AIzaSyAg5p0OR-RG5an0GzzhhcoRD-FD7bDOcz4\"\n",
    "            img = Image.open(urllib.request.urlopen(url)).convert(\"RGB\")\n",
    "            img = np.array(img)\n",
    "            X[count, :, :, :] = img\n",
    "            \n",
    "            village_code = f1.iloc[j, 0]\n",
    "            y[count, :] = np.array(f2[(f2.village_code == village_code)])[0, 1:]\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "    model1.train_on_batch(X, [y[:, 0:9], y[:, 9:15], y[:, 15:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.6361498e-03, 2.2046155e-05, 8.5435779e-05, 1.7676927e-02,\n",
       "         3.4429564e-04, 3.1025970e-01, 6.6389704e-01, 1.9144827e-05,\n",
       "         5.0592287e-03]], dtype=float32),\n",
       " array([[1.9839518e-02, 1.3054203e-09, 8.5810706e-02, 4.3386254e-02,\n",
       "         8.4195328e-01, 9.0102386e-03]], dtype=float32),\n",
       " array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = LOCCODE_BASE_URL + str(f1.iloc[0, 5]) + \",\" + str(f1.iloc[0, 6]) + \"&zoom=16&size=1920x1920&maptype=satellite&key=AIzaSyAg5p0OR-RG5an0GzzhhcoRD-FD7bDOcz4\"\n",
    "img = Image.open(urllib.request.urlopen(url)).convert(\"RGB\")\n",
    "img = np.array(img)\n",
    "X_test = img.reshape(1, 640, 640, 3)\n",
    "\n",
    "village_code = f1.iloc[0, 0]\n",
    "y_test = np.array(f2[(f2.village_code == village_code)])[0, 1:]\n",
    "#model1.test_on_batch(X_test, [y_test[0:9].reshape(1, 9), y_test[9:15].reshape(1, 6), y_test[15:].reshape(1, 10)])\n",
    "model1.predict_on_batch(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 % done\n",
      "1 % done\n",
      "2 % done\n",
      "3 % done\n",
      "4 % done\n",
      "5 % done\n",
      "6 % done\n",
      "7 % done\n",
      "8 % done\n",
      "9 % done\n",
      "10 % done\n",
      "11 % done\n",
      "12 % done\n",
      "13 % done\n",
      "14 % done\n",
      "15 % done\n",
      "16 % done\n",
      "17 % done\n",
      "18 % done\n",
      "19 % done\n",
      "20 % done\n",
      "21 % done\n",
      "22 % done\n",
      "23 % done\n",
      "24 % done\n",
      "25 % done\n",
      "26 % done\n",
      "27 % done\n",
      "28 % done\n",
      "29 % done\n",
      "30 % done\n",
      "31 % done\n",
      "32 % done\n",
      "33 % done\n",
      "34 % done\n",
      "35 % done\n",
      "36 % done\n",
      "37 % done\n",
      "38 % done\n",
      "39 % done\n",
      "40 % done\n",
      "41 % done\n",
      "42 % done\n",
      "43 % done\n",
      "44 % done\n",
      "45 % done\n",
      "46 % done\n",
      "47 % done\n",
      "48 % done\n",
      "49 % done\n",
      "50 % done\n",
      "51 % done\n",
      "52 % done\n",
      "53 % done\n",
      "54 % done\n",
      "55 % done\n",
      "56 % done\n",
      "57 % done\n",
      "58 % done\n",
      "59 % done\n",
      "60 % done\n",
      "61 % done\n",
      "62 % done\n",
      "63 % done\n",
      "64 % done\n",
      "65 % done\n",
      "66 % done\n",
      "67 % done\n",
      "68 % done\n",
      "69 % done\n",
      "70 % done\n",
      "71 % done\n",
      "72 % done\n",
      "73 % done\n",
      "74 % done\n",
      "75 % done\n",
      "76 % done\n",
      "77 % done\n",
      "78 % done\n",
      "79 % done\n",
      "80 % done\n",
      "81 % done\n",
      "82 % done\n",
      "83 % done\n",
      "84 % done\n",
      "85 % done\n",
      "86 % done\n",
      "87 % done\n",
      "88 % done\n",
      "89 % done\n",
      "90 % done\n",
      "91 % done\n",
      "92 % done\n",
      "93 % done\n",
      "94 % done\n",
      "95 % done\n",
      "96 % done\n",
      "97 % done\n",
      "98 % done\n",
      "99 % done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.11081306, 0.11081306, 0.11114381, 0.11081306, 0.11267308,\n",
       "         0.11115429, 0.11081306, 0.11081306, 0.11096352]], dtype=float32),\n",
       " array([[0.16535014, 0.16535014, 0.16535014, 0.16768906, 0.16535014,\n",
       "         0.17091034]], dtype=float32),\n",
       " array([[0.09932344, 0.09932344, 0.09932344, 0.09932344, 0.10038717,\n",
       "         0.09932344, 0.10255377, 0.09932344, 0.10147534, 0.0996431 ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCCODE_BASE_URL = \"https://maps.googleapis.com/maps/api/staticmap?center=\"\n",
    "\n",
    "f1 = pd.read_csv('region_info_train.csv')\n",
    "f2 = pd.read_csv('region_info_train_y.csv')\n",
    "\n",
    "url = LOCCODE_BASE_URL + str(f1.iloc[3, 5]) + \",\" + str(f1.iloc[3, 6]) + \"&zoom=16&size=1920x1920&maptype=satellite&key=AIzaSyAg5p0OR-RG5an0GzzhhcoRD-FD7bDOcz4\"\n",
    "img = Image.open(urllib.request.urlopen(url)).convert(\"RGB\")\n",
    "img = np.array(img)\n",
    "X_train = img.reshape(1, 640, 640, 3)\n",
    "\n",
    "village_code = f1.iloc[3, 0]\n",
    "y_train = np.array(f2[(f2.village_code == village_code)])[0, 1:]\n",
    "\n",
    "for i in range(1000):\n",
    "    if i % 10 == 0:\n",
    "        print(i//10, \"% done\")\n",
    "        \n",
    "    model1.train_on_batch(X_train, [y_train[0:9].reshape(1, -1), y_train[9:15].reshape(1, -1), y_train[15:].reshape(1, -1)])\n",
    "\n",
    "model1.predict_on_batch(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
